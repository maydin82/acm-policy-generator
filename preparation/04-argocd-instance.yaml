apiVersion: argoproj.io/v1beta1
kind: ArgoCD
metadata:
  name: openshift-gitops
  namespace: openshift-gitops
spec:
  server:
    extraCommandArgs:
      - '--enable-gzip'
    autoscale:
      enabled: true
    env:
      - name: ARGOCD_SERVER_ENABLE_GZIP
        value: 'true'
      - name: ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS
        value: '120'
    grpc:
      ingress:
        enabled: false
    ingress:
      enabled: false
    resources:
      limits:
        cpu: '1'
        memory: 2Gi
      requests:
        cpu: 250m
        memory: 512Mi
    route:
      enabled: true
    service:
      type: ''
  grafana:
    enabled: false
    ingress:
      enabled: false
    resources:
      limits:
        cpu: 500m
        memory: 256Mi
      requests:
        cpu: 25m
        memory: 128Mi
    route:
      enabled: false
  resourceTrackingMethod: annotation
  monitoring:
    enabled: false
  notifications:
    enabled: true
  prometheus:
    enabled: false
    ingress:
      enabled: false
    route:
      enabled: false
  initialSSHKnownHosts: {}
  sso:
    dex:
      openShiftOAuth: true
      resources:
        limits:
          cpu: 500m
          memory: 256Mi
        requests:
          cpu: 250m
          memory: 56Mi
    provider: dex
  applicationSet:
    resources:
      limits:
        cpu: '2'
        memory: 1Gi
      requests:
        cpu: 500m
        memory: 256Mi
    webhookServer:
      ingress:
        enabled: false
      route:
        enabled: false
  rbac:
    defaultPolicy: 'role:none'
    policy: |
      # Access Control
      p, role:none, applications, get, */*, deny
      p, role:none, certificates, get, *, deny
      p, role:none, clusters, get, *, deny
      p, role:none, repositories, get, *, deny
      p, role:none, projects, get, *, deny
      p, role:none, accounts, get, *, deny
      p, role:none, gpgkeys, get, *, deny
      p, pipeline, applications, get, */*,allow
      p, pipeline, applications, sync, */*,allow
      p, pipeline, projects, get, *, allow
      g, system:cluster-admins, role:admin
      g, cluster-admins, role:admin
    scopes: '[groups]'
  extraConfig:
    accounts.pipeline: apiKey
    globalProjects: |-
      - labelSelector:
          matchExpressions:
            - key: argocd.argoproj.io/project-inherit
              operator: In
              values:
                - global-project-template
                - global
        projectName: global-project-template
    resource.compareoptions: |
      ignoreResourceStatusField: all
    resource.customizations.ignoreResourceUpdates.all: |
      jsonPointers:
      - /status
    resource.ignoreResourceUpdatesEnabled: 'true'
  kustomizeBuildOptions: --enable-alpha-plugins --enable-helm ##ACM related
  repo:
    resources:
      limits:
        cpu: '2'
        memory: 2Gi
      requests:
        cpu: 500m
        memory: 512Mi

    env:
      - name: ARGOCD_HELM_ALLOW_CONCURRENCY
        value: 'true'
      - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT
        value: '50'
      - name: ARGOCD_GIT_ATTEMPTS_COUNT
        value: '3'
      - name: ARGOCD_EXEC_TIMEOUT
        value: 3m
      - name: KUSTOMIZE_PLUGIN_HOME  #ACM related
        value: /etc/kustomize/plugin
      - name: POLICY_GEN_ENABLE_HELM #ACM related
        value: "true"
    initContainers: ## ACM related
    - args:
      - -c
      - cp /policy-generator/PolicyGenerator-not-fips-compliant /policy-generator-tmp/PolicyGenerator
      command:
      - /bin/bash
      image: registry.redhat.io/rhacm2/multicluster-operators-subscription-rhel9@sha256:8151a89ebfebf2e6d336849fdd329b123b7f486938808ee80bf6bd8d44f6985c
      name: policy-generator-install
      volumeMounts:
      - mountPath: /policy-generator-tmp
        name: policy-generator
    volumeMounts:
    - mountPath: /etc/kustomize/plugin/policy.open-cluster-management.io/v1/policygenerator
      name: policy-generator
    volumes:
    - emptyDir: {}
      name: policy-generator
  resourceExclusions: |
    - apiGroups:
      - policy.open-cluster-management.io
      clusters:
      - '*'
      kinds:
      - ConfigurationPolicy
    - apiGroups:
      - compliance.openshift.io
      kinds:
      - ComplianceCheckResult
      - ComplianceRemediation
    - apiGroups:
      - tekton.dev
      clusters:
      - '*'
      kinds:
      - TaskRun
      - PipelineRun
  resourceHealthChecks:
    - check: |
        hs = {}
        if obj.spec.disabled ~= nil and obj.spec.disabled == true then
          hs.status = "Healthy"
          return hs
        end
        if obj.status == nil or obj.status.compliant == nil then
          hs.status = "Progressing"
          hs.message = "Waiting for the status to be reported"
          return hs
        end
        if obj.status.compliant == "Compliant" then
          hs.status = "Healthy"
        else
          hs.status = "Degraded"
        end
        noncompliants = {}
        if obj.status.status ~= nil then
          -- "root" policy
          for i, entry in ipairs(obj.status.status) do
            if entry.compliant ~= "Compliant" then
              table.insert(noncompliants, entry.clustername)
            end
          end
          if #noncompliants == 0 then
            hs.message = "All clusters are compliant"
          else
            hs.message = "NonCompliant clusters: " .. table.concat(noncompliants, ", ")
          end
        elseif obj.status.details ~= nil then
          -- "replicated" policy
          for i, entry in ipairs(obj.status.details) do
            if entry.compliant ~= "Compliant" then
              table.insert(noncompliants, entry.templateMeta.name)
            end
          end
          if #noncompliants == 0 then
            hs.message = "All templates are compliant"
          else
            hs.message = "NonCompliant templates: " .. table.concat(noncompliants, ", ")
          end
        end
        return hs
      group: policy.open-cluster-management.io
      kind: Policy
    - check: |
        hs = {}
        hs.status = "Progressing"
        hs.message = ""
        if obj.status ~= nil then
          if obj.status.health ~= nil then
            hs.status = obj.status.health.status
            if obj.status.health.message ~= nil then
              hs.message = obj.status.health.message
            end
          end
        end
        return hs
      group: argoproj.io
      kind: Application
    - check: |
        health_status = {}
        if obj.status ~= nil then
          if obj.status.conditions ~= nil then
            numDegraded = 0
            numPending = 0
            msg = ""
            for i, condition in pairs(obj.status.conditions) do
              msg = msg .. i .. ": " .. condition.type .. " | " .. condition.status .. "\n"
              if condition.type == "InstallPlanPending" and condition.status == "True" then
                numPending = numPending + 1
              elseif (condition.type == "InstallPlanMissing" and condition.reason ~= "ReferencedInstallPlanNotFound") then
                numDegraded = numDegraded + 1
              elseif (condition.type == "CatalogSourcesUnhealthy" or condition.type == "InstallPlanFailed" or condition.type == "ResolutionFailed") and condition.status == "True" then
                numDegraded = numDegraded + 1
              end
            end
            if numDegraded == 0 and numPending == 0 then
              health_status.status = "Healthy"
              health_status.message = msg
              return health_status
            elseif numPending > 0 and numDegraded == 0 then
              health_status.status = "Progressing"
              health_status.message = "An install plan for a subscription is pending installation"
              return health_status
            else
              health_status.status = "Degraded"
              health_status.message = msg
              return health_status
            end
          end
        end
        health_status.status = "Progressing"
        health_status.message = "An install plan for a subscription is pending installation"
        return health_status
      group: operators.coreos.com
      kind: Subscription
    - check: |
        hs = {}
        if obj.status ~= nil then
          if obj.status.phase ~= nil then
            if obj.status.phase == "Complete" then
              hs.status = "Healthy"
              hs.message = obj.status.phase
              return hs
            end
          end
        end
        hs.status = "Progressing"
        hs.message = "Waiting for InstallPlan to complete"
        return hs
      group: operators.coreos.com
      kind: InstallPlan
    - check: |
        hs = {}
        if obj.status ~= nil and obj.status.conditions ~= nil then
            for i, condition in ipairs(obj.status.conditions) do
              if condition.status == "True" or condition.reason == "InstallSuccessful" or condition.reason == "UpgradeSuccessful" then
                  hs.status = "Healthy"
                  hs.message = "Install Successful"
                  return hs
              end
            end
        end
        hs.status = "Progressing"
        hs.message = "Waiting for Central to deploy."
        return hs
      group: platform.stackrox.io
      kind: Central
    - check: |
        hs = {}
        hs.status = "Progressing"
        hs.message = ""
        if obj.status ~= nil then
          if obj.status.tags ~= nil then
            numTags = 0
            for _ , item in pairs(obj.status.tags) do
              numTags = numTags + 1
              numItems = 0
              if item.tags ~= nil then
                for _ , item in pairs(item.tags) do
                  numItems = numItems + 1
                end
                if numItems == 0 then
                  return hs
                end
              end
            end
            if numTags > 0 then
              hs.status = "Healthy"
              hs.message = "ImageStream has tags resolved"
              return hs
            end
          end
        end
        return hs
      group: image.openshift.io
      kind: ImageStream
    - check: |
        hs = {}
        if obj.status ~= nil then
          if obj.status.phase ~= nil then
            if obj.status.phase == "Complete" then
              hs.status = "Healthy"
              hs.message = obj.status.phase
              return hs
            end
          end
        end
        hs.status = "Progressing"
        hs.message = "Waiting for Build to complete"
        return hs
      group: build.openshift.io
      kind: Build
    - check: |
        hs = {}
        if obj.status ~= nil then
          if obj.status.phase ~= nil then
            if obj.status.phase == "Pending" then
              hs.status = "Healthy"
              hs.message = obj.status.phase
              return hs
            end
            if obj.status.phase == "Bound" then
              hs.status = "Healthy"
              hs.message = obj.status.phase
              return hs
            end
          end
        end
        hs.status = "Progressing"
        hs.message = "Waiting for PVC"
        return hs
      kind: PersistentVolumeClaim
  resourceIgnoreDifferences:
    resourceIdentifiers:
      - customization:
          jsonPointers:
            - /status/ingress
            - /metadata/annotations
        group: route.openshift.io
        kind: Route
      - customization:
          jsonPointers:
            - /status/ingress
        group: quay.redhat.com
        kind: QuayRegistry
  ha:
    enabled: false
    resources:
      limits:
        cpu: 500m
        memory: 256Mi
      requests:
        cpu: 25m
        memory: 28Mi
  kustomizeBuildOptions: '--enable-alpha-plugins --enable-helm'
  tls:
    ca: {}
  redis:
    resources:
      limits:
        cpu: '2'
        memory: 2Gi
      requests:
        cpu: 250m
        memory: 512Mi
  controller:
    env:
      - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS
        value: '120'
      - name: ARGOCD_K8S_CLIENT_QPS
        value: '350'
      - name: ARGOCD_K8S_CLIENT_BURST
        value: '350'
      - name: ARGOCD_RECONCILIATION_JITTER
        value: 3m
      - name: ARGOCD_K8S_TCP_TIMEOUT
        value: 60s
    logLevel: info
    processors: {}
    resources:
      limits:
        cpu: '4'
        memory: 8Gi
      requests:
        cpu: '1'
        memory: 2Gi
    sharding: {}

